import java.text.SimpleDateFormat
import java.util.Calendar
import java.nio.file.{Files, Paths, StandardCopyOption}
import org.apache.hadoop.fs.{FileSystem, Path}

// Step 1: Get the current time and day to dynamically create folder paths
val currentTime = new SimpleDateFormat("yyyyMMddHHmmss").format(Calendar.getInstance().getTime)
val currentDay = new SimpleDateFormat("EEEE").format(Calendar.getInstance().getTime)  // Current day (e.g., Friday)

// Step 2: Define temporary and final output paths
val tempOutputPath = s"/tmp/tmp_RBSCC_${currentTime}"  // Local temporary directory for part files
val hdfsOutputPath = s"hdfs:///disk/output/${currentTime}_RBSCSS_${currentDay}"  // HDFS path for intermediate part files
val finalOutputPath = s"/disk1/bigdata/ramp/${currentTime}_RBSCSS_${currentDay}/master1.csv"  // Final output path

// Step 3: Write DataFrame to HDFS (This will create part files in HDFS)
masterdf.coalesce(1).write
  .option("header", "true")
  .mode("overwrite")
  .csv(hdfsOutputPath)  // Writing to HDFS

println(s"Data written to HDFS path: $hdfsOutputPath")

// Step 4: Get the part files from the HDFS output directory
val hadoopConf = spark.sparkContext.hadoopConfiguration
val fs = FileSystem.get(hadoopConf)
val outputDirPath = new Path(hdfsOutputPath)
val partFiles = fs.listStatus(outputDirPath).filter(f => f.getPath.getName.startsWith("part"))

if (partFiles.nonEmpty) {
  // Step 5: Move the part file to the local /tmp folder and rename it
  val partFile = partFiles(0).getPath  // Only one part file after coalesce(1)
  val tempFilePath = s"/tmp/${partFile.getName}"
  val outputTempPath = new Path(tempFilePath)
  
  // Move part file from HDFS to local /tmp folder
  fs.copyToLocalFile(partFile, outputTempPath)
  println(s"Part file copied to local temporary path: $tempFilePath")

  // Step 6: Rename part file to master1.csv and move it to final location
  val masterCsvPath = s"/tmp/master1.csv"
  Files.move(Paths.get(tempFilePath), Paths.get(masterCsvPath), StandardCopyOption.REPLACE_EXISTING)

  // Step 7: Copy the final CSV to the desired location on the local system
  val finalPath = Paths.get(finalOutputPath)
  Files.move(Paths.get(masterCsvPath), finalPath, StandardCopyOption.REPLACE_EXISTING)

  println(s"Final CSV file has been moved to: $finalOutputPath")
} else {
  println(s"No part files found at HDFS output path: $hdfsOutputPath")
}
