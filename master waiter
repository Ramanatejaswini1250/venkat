import org.apache.spark.sql.{SparkSession, DataFrame}
import scala.util.Try

def waitForDataToLoadAndValidate(
  spark: SparkSession,
  alertCode: String,
  jdbcUrl: String,
  jdbcUser: String,
  jdbcPassword: String,
  jdbcDriver: String,
  maxRetries: Int = 10,
  retryInterval: Long = 10000
): (Boolean, Long, Long) = {

  var retries = 0
  var dataLoaded = false
  var master1Count: Long = 0
  var master2Count: Long = 0

  while (retries < maxRetries && !dataLoaded) {
    println(s"[Attempt ${retries + 1}] Checking data for alertCode: $alertCode")

    val masterTargetCountQuery =
      s"""
      |SELECT 
      |  (SELECT COUNT(*) FROM U_D_DSV_001_RSS_0.RAMP_MASTER_TARGET1_TEST WHERE alertCode = '$alertCode') AS master1_count,
      |  (SELECT COUNT(*) FROM U_D_DSV_001_RSS_0.RAMP_MASTER_TARGET2_TEST WHERE alertCode = '$alertCode') AS master2_count
      """.stripMargin

    try {
      val countDF = spark.read
        .format("jdbc")
        .option("url", jdbcUrl)
        .option("dbtable", s"($masterTargetCountQuery) AS subquery")
        .option("user", jdbcUser)
        .option("password", jdbcPassword)
        .option("driver", jdbcDriver)
        .load()

      val row = countDF.collect().headOption
      master1Count = row.map(_.getAs[Long]("master1_count")).getOrElse(0L)
      master2Count = row.map(_.getAs[Long]("master2_count")).getOrElse(0L)

      println(s"Retrieved Master1 Count: $master1Count, Master2 Count: $master2Count")

      if (master1Count > 0 && master2Count > 0) {
        println(s"‚úÖ Data is available for alertCode: $alertCode")
        dataLoaded = true
      } else {
        println(s"‚ùå Data not fully available yet (Master1: $master1Count, Master2: $master2Count). Retrying in ${retryInterval / 1000} seconds...")
        retries += 1
        Thread.sleep(retryInterval)
      }

    } catch {
      case e: Exception =>
        println(s"‚ö†Ô∏è Error executing query: ${e.getMessage}")
        e.printStackTrace()
    }
  }

  if (!dataLoaded) {
    println(s"‚õî Data for alertCode: $alertCode was NOT fully loaded after $maxRetries retries.")
  }

  (dataLoaded, master1Count, master2Count)
}

val (dataLoaded, master1Count, master2Count) = waitForDataToLoadAndValidate(
  spark, alertCode, jdbcUrl, jdbcUser, jdbcPassword, jdbcDriver
)

if (dataLoaded) {
  println(s"üöÄ Proceeding with processing for alertCode: $alertCode")

  // Read both Master Tables only ONCE
  val master1DF = spark.read
    .format("jdbc")
    .option("url", jdbcUrl)
    .option("dbtable", "U_D_DSV_001_RSS_0.RAMP_MASTER_TARGET1_TEST")
    .option("user", jdbcUser)
    .option("password", jdbcPassword)
    .option("driver", jdbcDriver)
    .load()
    .filter(s"alertCode = '$alertCode'")

  val master2DF = spark.read
    .format("jdbc")
    .option("url", jdbcUrl)
    .option("dbtable", "U_D_DSV_001_RSS_0.RAMP_MASTER_TARGET2_TEST")
    .option("user", jdbcUser)
    .option("password", jdbcPassword)
    .option("driver", jdbcDriver)
    .load()
    .filter(s"alertCode = '$alertCode'")

  // Write both tables to HDFS
  val hdfsPath1 = s"/user/hdfs/ramp_master1/$alertCode"
  val hdfsPath2 = s"/user/hdfs/ramp_master2/$alertCode"

  master1DF.write.mode("overwrite").parquet(hdfsPath1)
  master2DF.write.mode("overwrite").parquet(hdfsPath2)

  println(s"‚úÖ Data written to HDFS:\n - Master1: $hdfsPath1\n - Master2: $hdfsPath2")
} else {
  println(s"‚õî Skipping processing for alertCode: $alertCode due to missing data.")
}
