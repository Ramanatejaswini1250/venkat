import org.apache.spark.sql.{SparkSession, Row, DataFrame}
import scala.util.Try

// Function to Wait for Data to be Available in Both Master Tables
def waitForDataToLoadAndValidate(
  spark: SparkSession,
  alertCode: String,
  countCheckQuery: String,
  jdbcUrl: String,
  jdbcUser: String,
  jdbcPassword: String,
  jdbcDriver: String,
  maxRetries: Int = 10,
  retryInterval: Long = 10000
): Boolean = {

  var retries = 0
  var dataLoaded = false

  while (retries < maxRetries && !dataLoaded) {
    println(s"[Attempt ${retries + 1}] Checking data for alertCode: $alertCode")

    try {
      val countDF = spark.read
        .format("jdbc")
        .option("url", jdbcUrl)
        .option("dbtable", s"($countCheckQuery) AS subquery")
        .option("user", jdbcUser)
        .option("password", jdbcPassword)
        .option("driver", jdbcDriver)
        .load()

      // Extract counts for both master tables
      val counts = Try {
        val row = countDF.collect().headOption
        row.map(r => (r.getAs[Long]("master1_count"), r.getAs[Long]("master2_count"))).getOrElse((0L, 0L))
      }.getOrElse((0L, 0L))

      val (master1Count, master2Count) = counts

      println(s"Retrieved Counts - Master1: $master1Count, Master2: $master2Count")

      if (master1Count > 0 && master2Count > 0) {
        println(s"‚úÖ Data is available for both Master Tables for alertCode: $alertCode")
        dataLoaded = true
      } else {
        println(s"‚ùå Data not available yet for alertCode: $alertCode. Retrying in ${retryInterval / 1000} seconds...")
        retries += 1
        Thread.sleep(retryInterval)
      }

    } catch {
      case e: Exception =>
        println(s"‚ö†Ô∏è Error executing query: ${e.getMessage}")
        e.printStackTrace()
    }
  }

  if (!dataLoaded) {
    println(s"‚õî Data for alertCode: $alertCode was NOT loaded after $maxRetries retries.")
  }

  dataLoaded
}

// Main foreachPartition Logic
df.foreachPartition { partition =>
  val spark = SparkSession.builder().getOrCreate()

  // JDBC Connection Details
  val jdbcUrl = "jdbc:mysql://your-db-host:3306/your-db"
  val jdbcUser = "your_user"
  val jdbcPassword = "your_password"
  val jdbcDriver = "com.mysql.cj.jdbc.Driver"

  // Extract Alert Code from Partition
  val alertCode = partition.map(row => row.getAs[String]("alert_code")).headOption.getOrElse("")

  if (alertCode.nonEmpty) {
    // Combined Query to Check Both Master Tables
    val masterTargetCountQuery =
      s"""
      |SELECT 
      |  (SELECT COUNT(*) FROM U_D_DSV_001_RSS_0.RAMP_MASTER_TARGET1_TEST WHERE alertCode = '$alertCode') AS master1_count,
      |  (SELECT COUNT(*) FROM U_D_DSV_001_RSS_0.RAMP_MASTER_TARGET2_TEST WHERE alertCode = '$alertCode') AS master2_count
      """.stripMargin

    val dataLoaded = waitForDataToLoadAndValidate(
      spark,
      alertCode,
      masterTargetCountQuery,
      jdbcUrl,
      jdbcUser,
      jdbcPassword,
      jdbcDriver
    )

    if (dataLoaded) {
      println(s"üöÄ Data is ready for alertCode: $alertCode. Proceeding with partition processing...")
      
      partition.foreach { row =>
        // Your existing logic for processing each row
        println(s"Processing row: ${row}")
      }

    } else {
      println(s"‚õî Skipping partition for alertCode: $alertCode as data was not loaded in time.")
    }
  } else {
    println("‚ö†Ô∏è No alertCode found in this partition. Skipping...")
  }
}
