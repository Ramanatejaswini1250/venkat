def waitForDataToLoadAndValidate(countCheckQuery: String, dtCount: Int, maxRetries: Int = 10, retryInterval: Long = 10000): Boolean = {
  var retries = 0
  var dataLoaded = false

  while (retries < maxRetries && !dataLoaded) {
    val countDF = spark.read
      .format("jdbc")
      .option("url", jdbcUrl)
      .option("dbtable", countCheckQuery)
      .option("user", jdbcUser)
      .option("password", jdbcPassword)
      .option("driver", jdbcDriver)
      .load()

    val count = countDF.collect()(0).getAs[Long]("count")

    if (count > 0) {
      dataLoaded = true
    } else {
      println(s"Waiting for data to be loaded into the master table. Retry #$retries...")
      Thread.sleep(retryInterval) // Wait before retrying
      retries += 1
    }
  }

  if (!dataLoaded) {
    println("Data was not loaded into the master table after maximum retries.")
  }
  
  dataLoaded
}

df.foreachPartition { partition =>
  partition.foreach { row =>
    val alertCode = row.getAs[String]("alert_code")
    val dtCount = row.getAs[Int]("dt_count")
    val dateToLoad = row.getAs[String]("date_to_load")
    val bteqLocation = row.getAs[String]("bteq_location")
    val emailAddress = row.getAs[String]("email_address")
    val business = row.getAs[String]("business")
    val sourceTableName = row.getAs[String]("source_table_name").getOrElse {
      sendEmailNotification(alertCode, "Missing source_table_name", emailAddress, business)
      throw new Exception("Missing source_table_name")
    }

    val frequency = row.getAs[String]("frequency").getOrElse {
      sendEmailNotification(alertCode, "Missing frequency", emailAddress, business)
      throw new Exception("Missing frequency")
    }

    val filterColumn = row.getAs[String]("filter_column").getOrElse {
      sendEmailNotification(alertCode, "Missing filter_column", emailAddress, business)
      throw new Exception("Missing filter_column")
    }

    // Validate that dtCount > 0
    if (dtCount > 0) {
      try {
        // Check the source table count
        val jdbcQuery = s"(SELECT COUNT(*) AS cnt FROM $sourceTableName WHERE $filterColumn = '$dateToLoad') AS subquery"

        val sourceTableCountDF = spark.read
          .format("jdbc")
          .option("url", jdbcUrl)
          .option("dbtable", jdbcQuery)
          .option("user", jdbcUser)
          .option("password", jdbcPassword)
          .option("driver", jdbcDriver)
          .load()

        val sourceTableCount = sourceTableCountDF.collect()(0).getAs[Long]("cnt")

        if (sourceTableCount == dtCount) {
          // Run the SQL script to load data into the master tables
          val sqlFolderPath = getSqlFolderPath(frequency, bteqLocation)

          if (Files.exists(Paths.get(sqlFolderPath))) {
            val sqlFilePath = s"$sqlFolderPath/${alertCode}.sql"

            if (Files.exists(Paths.get(sqlFilePath))) {
              runSqlScript(sqlFilePath)
              sendEmailNotification(alertCode, "SQL script executed successfully", emailAddress, business)

              // Step 1: Wait for data to be loaded into master tables before proceeding with validation
              val rampMasterTarget1CountQuery = "(SELECT COUNT(*) AS count FROM U_D_DSV_001_RSS_O.RAMP_MASTER_TARGET1) AS subquery"
              val rampMasterTarget2CountQuery = "(SELECT COUNT(*) AS count FROM U_D_DSV_001_RSS_O.RAMP_MASTER_TARGET2) AS subquery"

              // Wait for data to be loaded into both master tables
              val masterTarget1DataLoaded = waitForDataToLoadAndValidate(rampMasterTarget1CountQuery, dtCount)
              val masterTarget2DataLoaded = waitForDataToLoadAndValidate(rampMasterTarget2CountQuery, dtCount)

              if (masterTarget1DataLoaded && masterTarget2DataLoaded) {
                // Step 2: Validate master table counts after ensuring data is loaded
                println("Data loaded successfully into RAMP_MASTER_TARGET1 and RAMP_MASTER_TARGET2. Proceeding with count validation...")

                // Master table count validation
                val masterTargetCount1 = spark.read
                  .format("jdbc")
                  .option("url", jdbcUrl)
                  .option("dbtable", rampMasterTarget1CountQuery)
                  .option("user", jdbcUser)
                  .option("password", jdbcPassword)
                  .option("driver", jdbcDriver)
                  .load()
                  .collect()(0)
                  .getAs[Long]("count")

                val masterTargetCount2 = spark.read
                  .format("jdbc")
                  .option("url", jdbcUrl)
                  .option("dbtable", rampMasterTarget2CountQuery)
                  .option("user", jdbcUser)
                  .option("password", jdbcPassword)
                  .option("driver", jdbcDriver)
                  .load()
                  .collect()(0)
                  .getAs[Long]("count")

                if (masterTargetCount1 != dtCount || masterTargetCount2 != dtCount) {
                  val message = s"Master table count validation failed. Counts: RAMP_MASTER_TARGET1 ($masterTargetCount1), RAMP_MASTER_TARGET2 ($masterTargetCount2), expected dtCount ($dtCount)"
                  sendEmailNotification(alertCode, message, emailAddress, business)
                  println(message)
                  throw new Exception(message)
                } else {
                  println(s"Master table count validation passed for both tables. Counts: RAMP_MASTER_TARGET1 ($masterTargetCount1), RAMP_MASTER_TARGET2 ($masterTargetCount2).")

                  // Continue with further blank value checks and archiving if necessary...
                }
              } else {
                val message = "Data not loaded into master tables within the allowed time, skipping validation."
                sendEmailNotification(alertCode, message, emailAddress, business)
                println(message)
              }
            } else {
              val message = s"SQL file not found for alertCode: $alertCode"
              sendEmailNotification(alertCode, message, emailAddress, business)
              println(message)
            }
          } else {
            val message = s"Folder not found for frequency: $frequency at path: $sqlFolderPath"
            sendEmailNotification(alertCode, message, emailAddress, business)
            println(message)
          }
        } else {
          val message = s"Source table count does not match DT_COUNT"
          sendEmailNotification(alertCode, message, emailAddress, business)
          println(message)
        }
      } catch {
        case e: Exception =>
          val message = s"Validation failed for alertCode: $alertCode with error: ${e.getMessage}"
          sendEmailNotification(alertCode, message, emailAddress, business)
          println(message)
      }
    } else {
      val message = "dtCount is not greater than 0, skipping validation"
      sendEmailNotification(alertCode, message, emailAddress, business)
      println(message)
    }
  }
}
