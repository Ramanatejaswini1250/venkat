# Get a list of all .sql files in the Daily directory
sqlFiles=$(ls /disk1/bigdata/dev/source/ramp/testing2/etl-ramp-automation/run/sql/Daily/*.sql)

# List your properties files
propertiesFiles="/disk1/bigdata/dev/source/ramp/testing2/etl-ramp-automation/run/sql/jdbc_properties.properties,/disk1/bigdata/dev/source/ramp/testing2/etl-ramp-automation/run/sql/email_properties.properties"

# Combine all the files
filesToInclude="$sqlFiles,$propertiesFiles"

# Submit your Spark job with all the files
spark-submit \
  --class your.main.class.name \
  --master yarn \
  --deploy-mode client \
  --files $filesToInclude \
  your_spark_application.jar \
  --frequency Daily \
  --bteqLocation /disk1/bigdata/dev/source/ramp/testing2/etl-ramp-automation/run/sql
