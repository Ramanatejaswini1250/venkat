// Initialize an empty list to hold rows
var rows_master1 = List[Row]()

// Iterate through the ResultSet and collect rows
if (masterTable1.isBeforeFirst()) {
  masterTable1.beforeFirst()  // Reset to the first row
  while (masterTable1.next()) {
    // Extract values safely based on column names
    val rowValues = (1 to columnCount).map { i =>
      val columnName = metaData.getColumnName(i).toLowerCase
      columnName match {
        case "alert_id" => columnName -> Option(masterTable1.getString(i)).getOrElse(null)
        case "alert_code" => columnName -> try {
          Option(masterTable1.getString(i)).flatMap(s => Option(s.toInt)).getOrElse(null)
        } catch {
          case _: Exception => null
        }
        case "business_line" => columnName -> Option(masterTable1.getString(i)).getOrElse(null)
        case "event_timestamp" => columnName -> Option(masterTable1.getString(i)).getOrElse(null)
        case _ => columnName -> Option(masterTable1.getString(i)).getOrElse(null)
      }
    }.toMap

    // Print the row for debugging purposes
    println("Row Data: " + rowValues.mkString(", "))

    // Create a Row and add to the list
    rows_master1 = rows_master1 :+ Row.fromSeq(rowValues.values.toSeq)
  }

  // Convert List of Rows to DataFrame
  val masterTable1DF = spark.createDataFrame(
    spark.sparkContext.parallelize(rows_master1),
    schema_master1  // Ensure this matches the columns in the ResultSet
  )

  // Show the DataFrame
  masterTable1DF.show()

  // Optional: You can apply transformations, such as formatting the timestamp
  val formattedDF = masterTable1DF.withColumn(
    "formatted_event_timestamp",
    date_format(col("event_timestamp"), "yyyy-MM-dd HH:mm:ss")
  )

  // Show the transformed DataFrame
  formattedDF.show()

} else {
  println("No records found in the ResultSet!")
}
