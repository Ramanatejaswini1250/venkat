import org.apache.spark.sql.{SQLContext, DataFrame}
import org.apache.spark.SparkContext
import java.io.{BufferedReader, InputStreamReader}
import java.text.SimpleDateFormat
import java.util.{Calendar, Date}
import scala.util.{Try, Success, Failure}
import java.nio.file.{Files, Paths}
import java.sql.{Connection, DriverManager}

object EmailNotificationApp {
  
  // Define SparkContext (initialize the Spark context)
  val sc: SparkContext = new SparkContext("local[*]", "EmailNotificationApp")
  val sqlContext = new SQLContext(sc)  // Using SQLContext instead of SparkSession
  
  // JDBC connection parameters (to be set with actual values)
  val jdbcUrl: String = "jdbc:your_database_url"
  val jdbcUser: String = "your_user"
  val jdbcPassword: String = "your_password"
  val jdbcDriver: String = "com.jdbc.Driver"  // Specify the correct JDBC driver class

  // Function to send email notifications via a shell script with first email in To and others in CC
  def sendEmailNotification(alertCode: String, message: String, emailAddresses: String, business: String): Unit = {
    val shellScriptPath = "/path/to/email_notification.sh"  // Update with actual path to script
    val emailList = emailAddresses.split(",").map(_.trim)

    if (emailList.nonEmpty) {
      val toEmail = emailList(0)
      val ccEmails = emailList.drop(1).mkString(",")  // All remaining emails in "CC"

      Try {
        val process = new ProcessBuilder("bash", shellScriptPath, alertCode, message, toEmail, ccEmails, business).start()

        val reader = new BufferedReader(new InputStreamReader(process.getInputStream))
        var line: String = null
        while ({ line = reader.readLine(); line != null }) {
          println(line)
        }

        val exitCode = process.waitFor()
        if (exitCode != 0) {
          throw new Exception(s"Error executing shell script: $shellScriptPath with exit code: $exitCode")
        } else {
          println(s"Email notification sent to: $toEmail and CC: $ccEmails for alertCode: $alertCode with message: $message")
        }
      } match {
        case Success(_) => println(s"Notification sent for alertCode: $alertCode")
        case Failure(ex) => println(s"Failed to send email notification: ${ex.getMessage}")
      }
    } else {
      println("No email addresses found to send the notification.")
    }
  }

  // Function to run SQL script
  def runSqlScript(scriptPath: String): Unit = {
    // Implement running the SQL script here, e.g., using `sqlContext.sql()` or executing via command line
    println(s"Running SQL script at: $scriptPath")
    // Example:
    // val sqlContent = scala.io.Source.fromFile(scriptPath).getLines().mkString("\n")
    // sqlContext.sql(sqlContent)  // This is just a placeholder
  }

  // Function to generate a timestamped file name
  def getCurrentTimestamp: String = {
    val format = new SimpleDateFormat("yyyyMMddHHmmss")
    format.format(Calendar.getInstance().getTime)
  }

  def validateData(masterDF: DataFrame, fileDF: DataFrame): Boolean = {
    // Ensure both DataFrames are sorted
    val sortedMasterDF = masterDF.orderBy(masterDF.columns.map(col): _*)
    val sortedFileDF = fileDF.orderBy(fileDF.columns.map(col): _*)

    // Compare the two DataFrames
    val areEqual = sortedMasterDF.except(sortedFileDF).isEmpty &&
                   sortedFileDF.except(sortedMasterDF).isEmpty

    areEqual
  }

  def processRecords(df: DataFrame): Unit = {
    df.foreachPartition { partition =>
      partition.foreach { row =>
        val alertCode = row.getAs[String]("alert_code")
        val dtCount = row.getAs[Int]("dt_count")
        val dateToLoad = row.getAs[String]("date_to_load")
        val bteqLocation = row.getAs[String]("bteq_location")
        val emailAddress = row.getAs[String]("email_address")
        val business = row.getAs[String]("business")

        val sourceTableName = row.getAs[String]("source_table_name").getOrElse {
          sendEmailNotification(alertCode, "Missing source_table_name", emailAddress, business)
          throw new Exception("Missing source_table_name")
        }

        val frequency = row.getAs[String]("frequency").getOrElse {
          sendEmailNotification(alertCode, "Missing frequency", emailAddress, business)
          throw new Exception("Missing frequency")
        }

        val filterColumn = row.getAs[String]("filter_column").getOrElse {
          sendEmailNotification(alertCode, "Missing filter_column", emailAddress, business)
          throw new Exception("Missing filter_column")
        }

        try {
          if (dtCount > 0) {
            val jdbcQuery = s"(SELECT COUNT(*) AS cnt FROM $sourceTableName WHERE $filterColumn = '$dateToLoad') AS subquery"
            
            val sourceTableCountDF = sqlContext.read
              .format("jdbc")
              .option("url", jdbcUrl)
              .option("dbtable", jdbcQuery)
              .option("user", jdbcUser)
              .option("password", jdbcPassword)
              .option("driver", jdbcDriver)
              .load()

            val sourceTableCount = sourceTableCountDF.collect()(0).getAs[Long]("cnt")

            if (sourceTableCount == dtCount) {
              val sqlFolderPath = getSqlFolderPath(frequency, bteqLocation)
              
              if (Files.exists(Paths.get(sqlFolderPath))) {
                val sqlFilePath = s"$sqlFolderPath/${alertCode}.sql"
                
                if (Files.exists(Paths.get(sqlFilePath))) {
                  runSqlScript(sqlFilePath)
                  sendEmailNotification(alertCode, "SQL script executed successfully", emailAddress, business)
                } else {
                  val message = s"SQL file not found for alertCode: $alertCode"
                  sendEmailNotification(alertCode, message, emailAddress, business)
                  println(message)
                }
              } else {
                val message = s"Folder not found for frequency: $frequency at path: $sqlFolderPath"
                sendEmailNotification(alertCode, message, emailAddress, business)
                println(message)
              }
            } else {
              val message = s"Source table count does not match DT_COUNT"
              sendEmailNotification(alertCode, message, emailAddress, business)
              println(message)
            }
          } else {
            val message = s"DT_COUNT is less than or equal to 0 for alertCode: $alertCode"
            sendEmailNotification(alertCode, message, emailAddress, business)
            throw new Exception(message)
          }
        } catch {
          case ex: Exception =>
            val message = s"Error processing alertCode: $alertCode - ${ex.getMessage}"
            sendEmailNotification(alertCode, message, emailAddress, business)
            println(message)
            ex.printStackTrace()
        }
      }
    }
  }

  // Entry point for the Spark job
  def main(args: Array[String]): Unit = {
    // Simulate a DataFrame as an example (replace with actual DataFrame loading)
    val data = Seq(
      ("A001", 10, "2024-12-16", "/path/to/sql", Some("source_table"), Some("daily"), Some("filter_column")),
      ("A002", 5, "2024-12-17", "/path/to/sql", Some("source_table"), Some("hourly"), Some("filter_column"))
    )

    import sqlContext.implicits._
    val df = data.toDF("alert_code", "dt_count", "date_to_load", "bteq_location", "source_table_name", "frequency", "filter_column")

    // Process the records and send notifications
    processRecords(df)

    // Stop the Spark context
    sc.stop()
  }
}
