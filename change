import org.apache.hadoop.fs.{FileSystem, Path}
import org.apache.hadoop.conf.Configuration
import java.io.{BufferedReader, InputStreamReader}
import scala.collection.mutable.{Map, ListBuffer}

// Initialize Hadoop FileSystem and Path
val conf = new Configuration()
val fs = FileSystem.get(conf)
val csvPath1 = new Path("/output/path/master1.csv")  // Path to the CSV file

// Function to read the CSV file and count the records for each alertCode
def readCsvAndCount(filePath: Path): Map[String, Int] = {
  val reader = new BufferedReader(new InputStreamReader(fs.open(filePath), "UTF-8"))
  var line = reader.readLine() // Read the header (we'll discard it)
  val alertCodeCountMap = Map[String, Int]()

  // Loop through each line in the file and count occurrences of alertCode
  while (line != null) {
    val fields = line.split(",")
    if (fields.length >= 2) {  // Ensure we have both alert_id and alert_code
      val alertCode = fields(1).trim
      alertCodeCountMap(alertCode) = alertCodeCountMap.getOrElse(alertCode, 0) + 1
    }
    line = reader.readLine()
  }

  reader.close()
  alertCodeCountMap
}

// Read CSV data and get the counts for each alertCode
val csvAlertCodeCounts = readCsvAndCount(csvPath1)

// Sample mastertable1df to compare (you would already have this in your case)
val mastertable1df = Seq(
  ("1", "DC0019"),
  ("2", "DC0019"),
  ("3", "RA0387"),
  ("4", "RA0387"),
  ("5", "RA0387"),
  ("6", "RA0387")
)

// Group and count records by alertCode from mastertable1df
val mastertableAlertCodeCounts = mastertable1df.groupBy(_._2).map {
  case (alertCode, records) => (alertCode, records.length)
}

// Now, compare the counts from CSV and mastertable
csvAlertCodeCounts.foreach { case (alertCode, csvCount) =>
  val masterCount = mastertableAlertCodeCounts.getOrElse(alertCode, 0)
  if (csvCount == masterCount) {
    println(s"Alert $alertCode: Counts match - $csvCount records")
  } else {
    println(s"Alert $alertCode: Counts do not match - CSV: $csvCount, Master: $masterCount")
  }
}
