val issueType = if (frequency == null) {
    "Frequency Missing"
} else if (sourceTableName == null && filterColumn == null) {
    "All Three Missing (Frequency, Source, and Filter Column)"
} else if (sourceTableName == null) {
    "Source Table Name Missing"
} else if (filterColumn == null) {
    "Filter Column Missing"
} else if (frequency == null && sourceTableName == null) {
    "Frequency and Source Table Name Missing"
} else if (frequency == null && filterColumn == null) {
    "Frequency and Filter Column Missing"
} else if (sourceTableName == null && filterColumn == null) {
    "Source Table Name and Filter Column Missing"
} else {
    "Unknown Issue"
}

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.Row
import org.apache.spark.sql.types.{StructType, StructField, StringType}

val spark: SparkSession = SparkSession.builder()
    .appName("YourAppName")
    .getOrCreate()

import spark.implicits._  // Ensure this import is present

if (finalMissedAlerts.nonEmpty) {
    // Convert Set to Seq
    val missedAlertsSeq = finalMissedAlerts.toSeq.map(alertCode => Row(alertCode))

    // Define schema
    val schema = StructType(Array(
        StructField("alert_code", StringType, nullable = false)
    ))

    // Create DataFrame
    val missedAlertsDF = spark.createDataFrame(spark.sparkContext.parallelize(missedAlertsSeq), schema)

    // Proceed with join
    val businessContactsDF = df
        .join(missedAlertsDF, Seq("alert_code"), "inner")
        .select("alert_code", "business", "email_address")
        .distinct()
        .collect()
}

